---
title: "Road to Success: How to Kick Start at KickStarter"
author: "Chengwei Wang"
output:
  html_document:
    df_print: paged
    highlight: tango
    number_sections: no
    theme: paper
    toc: no
    toc_float: no
---

# Kickstarter Projects: Text Mining {.tabset}

> Analyzing 

```{r loading, message=FALSE, results='hide', warning=FALSE, echo = FALSE}
library(data.table)
library(tidyr)
library(dplyr)
library(ggplot2)
library(ggthemes)

library(tm)
library(quanteda)
library(tidytext)
#library(qdap)
library(wordcloud2)
library(plotrix)

library(rgdal)
library(leaflet)
library(RColorBrewer)
library(rgeos)

set.seed(42)

setwd("/Users/greatyifan/Desktop/resume/projects/dataviz/kickstarter/data/")
text <- read.csv("./kickstarter_projects_2020_02.csv", stringsAsFactors = F)

# check if all the rows are unique
# dim(text) == dim(unique(text))
# summary(text)

# change the date columns into date type
text$state_changed_at <- as.POSIXct(text$state_changed_at)
text$launched_at <- as.POSIXct(text$launched_at)

# add an index column
text$index <- 1:nrow(text)

#diy theme
diy_theme <- theme_economist_white(gray_bg = F, base_size = 10, 
                                   base_family = "georgia",horizontal = TRUE)+
  theme(panel.grid.major = element_line(size = .3),
        axis.line = element_line(colour = "black"))+
  theme_tufte(base_size=14, ticks=F) 
```

```{r datawrangling, results='hide', echo = FALSE}
# table(text$state)
# summary(text$pledged/text$goal)
# summary(text$backers_count)

#' any differences more than a certain number would be counted 1 day more,
#' e.g 35.1 days is converted to 36 days.
text$complish_days <- trunc(as.integer(text$state_changed_at - text$launched_at)/(3600*24)) + 1

text$money_per_backer <- text$pledged/text$backers_count
  
#summary(text$complish_days)
#summary(text$money_per_backer)
# table(text$top_category)
```

## 1. Identifying Successful Projects {.tabset}

### a) Success by Category

```{r, message=FALSE, results='hide', warning=FALSE, echo = FALSE}
df_category_success <- text %>% group_by(top_category) %>% summarise(success_rate = mean(state == 'successful'), exceed_money = median(pledged/goal), backers_count = median(backers_count), complish_days = mean(complish_days), pledged = median(pledged), money_per_backer = median(pledged/backers_count))

level <- df_category_success[order(df_category_success$success_rate, 
                                   decreasing = T),]$top_category
df_category_success$top_category <- factor(df_category_success$top_category, 
                                           levels = level)

text$top_category <- factor(text$top_category, 
                                           levels = level)
```

```{r Q1, warning=FALSE, message=FALSE, echo=FALSE, fig.height=8, fig.width=12, fig.align='center'}
ggplot(data = df_category_success) +
  geom_col(aes(x = top_category, y = success_rate), color="#05ce78", fill= "#05ce78", alpha = .9) +
  scale_y_continuous(name = '', expand = c(0,0)) + 
  diy_theme +
  labs(title = "Succeed Rate By Project Category", 
          subtitle = '',
          caption = '\n Source: Webrobots.io; Kickstarter') +
  theme(plot.subtitle = element_text(color = 'grey'),
        axis.line = element_blank(),
        axis.title = element_blank(),
        plot.title = element_text(hjust = .5, size = 25),
        legend.position = c(.5,1.05),
        legend.title = element_blank(), 
        legend.direction = 'horizontal',
        panel.grid.major.y=element_line(size = .1, color = 'grey')) 
  
```

It seems that dance related projects are more likely to success than any other categories, while the food related projects are more than easily to fail. 


### b) Success by Location

```{r, echo=FALSE, message=FALSE, warning=FALSE, echo = FALSE}
df_state_success <- text %>% 
  filter(country == 'USA') %>%
  group_by(location_state) %>% 
  summarise(success_rate = mean(state == 'successful'), 
            exceed_money = median(pledged/goal), 
            backers_count = median(backers_count), 
            complish_days = mean(complish_days), 
            pledged = median(pledged), 
            money_per_backer = median(pledged/backers_count))
```

```{r import shp, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
shp <- "/Users/greatyifan/Desktop/resume/projects/dataviz/kickstarter/data/tl_2017_us_state"
state_poly <- readOGR(dsn = shp, layer = 'tl_2017_us_state')
```

```{r alter shp data, echo=FALSE, message=FALSE, warning=FALSE}
state_poly@data <- left_join(state_poly@data, 
                             df_state_success[,1:2], 
                             by = c('STUSPS' = 'location_state'))
```

```{r, echo=FALSE}
attr <- "Â© <a href='https://github.com/ChengweiWang3210'>Chengwei Wang</a>"
```

```{r leaflet, echo=FALSE, fig.retina=2, fig.height=6, fig.width=8, fig.align="center"}
leaflet(state_poly, options = leafletOptions(minZoom = 4, maxZoom = 18)) %>%
  setView(lng = -98.583333, lat = 39.833333, zoom = 4) %>%
  addProviderTiles(provider = "CartoDB.VoyagerNoLabels") %>%
  addTiles(attribution = attr) %>%
  addPolygons(stroke = T, weight = 1, smoothFactor = 0.5,
              color='#575cfb', opacity=1, 
              fillColor = ~colorQuantile('Greens', success_rate)(success_rate),
              fillOpacity = 1, 
              label = paste0(state_poly@data$NAME, ": ",
                            paste0(round(state_poly@data$success_rate,2)*100,'%')),
              labelOptions = labelOptions(direction = 'auto'))
```


##

## 2. Writing your success story {.tabset}



```{r, echo=FALSE}
### a) Cleaning the Text and Word Cloud
# pickout 1000 the most successful project
index_success <- text[text$state == 'successful',][order(text[text$state == 'successful',]$complish_days, decreasing = F)[1:1000], ]$index

# pickout 1000 unsuccessful project
index_fail <- text[!text$state %in% c('successful', 'live'),][order(text[!text$state %in% c('successful', 'live'),]$complish_days, decreasing = T)[1:1000], ]$index

# check there is no duplication in these two indexes
# table(index_fail %in% index_success)

index <- c(index_success, index_fail)

df_text <- data.frame(doc_id = 1:nrow(text[index,]), text = text[index,'blurb'], 
                      stringsAsFactors = F)
# make sure the document id should be named exactly as "doc_id"
df_text <- na.omit(df_text)
df_corpus <- VCorpus(DataframeSource(df_text))
```

```{r clean, echo=FALSE}
removeNumPunct <- function(x){gsub("[^[:alpha:][:space:]]*", "", x)}
clean_corpus <- function(corpus){
# corpus <- tm_map(corpus, removePunctuation)
  corpus <- tm_map(corpus, content_transformer(tolower))
  #corpus <- tm_map(corpus, content_transformer(replace_symbol))
  corpus <- tm_map(corpus, removeWords, c(stopwords("en")))  
    # We could add more stop words as above
  corpus <- tm_map(corpus, removeNumbers)
  corpus <- tm_map(corpus, content_transformer(removeNumPunct))
  corpus <- tm_map(corpus, stripWhitespace)
  return(corpus)
}
# Apply your customized function to the SOTU: sotu_clean
blurb_clean <- clean_corpus(df_corpus)
```

```{r stem, echo=FALSE}
blurb_stemmed <- tm_map(blurb_clean, stemDocument)

stemCompletion2 <- function(x, dictionary) {
   x <- unlist(strsplit(as.character(x), " "))
    # # Oddly, stemCompletion completes an empty string to
      # a word in dictionary. Remove empty string to avoid issue.
   x <- x[x != ""]
   x <- stemCompletion(x, dictionary=dictionary)
   x <- paste(x, sep="", collapse=" ")
   PlainTextDocument(stripWhitespace(x))
}
```

```{r, echo=FALSE}
blurb_dtm <- DocumentTermMatrix(blurb_stemmed)
blurb_dt <- tidy(blurb_dtm)

blurb_dt <- blurb_dt %>%
  mutate(document = as.integer(document)) %>%
  mutate(succeed = ifelse(document <= 1000, 1, 0))

blurb_tf_idf <- blurb_dt %>% 
  bind_tf_idf(term, document, count) %>%
  group_by(succeed) %>%
  arrange(desc(tf_idf))
```

```{r, echo=FALSE, include=FALSE}
#blurb_tf_idf$tf_idf <- blurb_tf_idf$tf_idf * 10
# wordcloud(words =  blurb_tf_idf[blurb_tf_idf$succeed == 1, ]$term,
#           freq =  blurb_tf_idf[blurb_tf_idf$succeed == 1, ]$tf_idf,
#           max.words = 100, scale = c(3.8,2))
wordcloud2(data = blurb_tf_idf[blurb_tf_idf$succeed == 1, c('term', 'tf_idf')][1:100,], 
           shuffle = F, size = 1)
```

```{r, echo=FALSE, include=FALSE}
wordcloud2(data = blurb_tf_idf[blurb_tf_idf$succeed == 0, c('term', 'tf_idf')][1:100,], 
           shuffle = F, size = 1)
```



### a) Success in words

```{r pyramid, include=TRUE, fig.retina=2, fig.height=8, fig.width=12, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
blurb_common <- blurb_tf_idf %>%
  group_by(succeed, term) %>%
  summarise(mean_tfidf = mean(tf_idf))
blurb_common <- blurb_common %>%
  arrange(succeed, desc(mean_tfidf))
common_terms <- unique(blurb_common$term[duplicated(blurb_common$term)])
top25 <- blurb_common %>%
  filter(term %in% common_terms) %>%
  spread(key = succeed, value = mean_tfidf, ) %>%
  arrange(desc(`1`)) %>%
  slice(1:25) %>%
  rename(failed = `0`, succeed = `1`)
pyramid.plot(lx = top25$failed, rx = top25$succeed, labels = top25$term, 
             top.labels = c('failed blurbs', 'terms', 'successful blurbs'), 
             lxcol = '#575cfb', rxcol = '#05ce78', 
             main = 'Successful Words in Both Successful and Unsuccessful Blurbs')
```


### b) Simplicity as a virtue

```{r , results='hide', echo=FALSE}
blurb_corpus <- corpus(text[index,'blurb'], docnames = 1:2000)
FK_blurb <- textstat_readability(blurb_corpus, measure = 'Flesch.Kincaid')
FK_blurb$words <- ntoken(blurb_corpus)
FK_blurb$succeed <- factor(rep(c(1,0),each = 1000))
# FK_blurb
```

```{r 2c, warning=FALSE, message=FALSE, include=TRUE, fig.retina=2, fig.height=8, fig.width=12, fig.align='center', echo=FALSE}
# ggplot(FK_blurb, aes(x = words, y = Flesch.Kincaid, color = succeed)) +
#   geom_jitter(alpha = .2) +
#   geom_smooth()

ggplot(FK_blurb, aes(x = succeed, y = Flesch.Kincaid, color = succeed)) +
  geom_violin(alpha = .2) +
  geom_jitter(alpha=.3) +
  geom_boxplot(width=.1) +
  scale_y_continuous(name = '', expand = c(0,0)) + 
  diy_theme +
  labs(title = "Does Word Simplicity Predict Success? \n", 
          subtitle = 'Fresch-Kincaid Score',
          caption = '\n Source: Webrobots.io; Kickstarter') +
  theme(plot.subtitle = element_text(color = 'grey'),
        axis.line = element_blank(),
        axis.title = element_blank(),
        plot.title = element_text(hjust = .5, size = 25),
        legend.position = 'none',
        legend.title = element_blank(),
        panel.grid.major.y=element_line(size = .1, color = 'grey')) +
  scale_x_discrete(labels = c('failed', 'succeed')) +
  scale_fill_manual(values=c("#575cfb", "#05ce78"))
```

To tell from the graph above, simiplicity does not necessaily indicate success.  

##


## 3. Sentiment {.tabset}


### a) Stay positive

```{r, echo=FALSE}
pos <- read.table("data/dictionaries/positive-words.txt", as.is=T)
neg <- read.table("data/dictionaries/negative-words.txt", as.is=T)

sentiment <- function(words, pos, neg){
  require(quanteda)
  tok <- quanteda::tokens(words)
  pos.count <- sum(tok[[1]]%in%pos[,1])
  neg.count <- sum(tok[[1]]%in%neg[,1])
  out <- (pos.count - neg.count)/(pos.count+neg.count)
  return(out)
}
```

```{r, fig.height=8, fig.width=12, fig.align='center', echo=FALSE}
x <- sapply(df_text$text, function(x) sentiment(x, pos, neg))

df_text$sentiment <- x
df_text$sentiment[df_text$sentiment == 'NaN'] = 0
df_text$sentiment[df_text$sentiment < 0] <- -1
df_text$sentiment[df_text$sentiment > 0] <- 1

df_text$success <- rep(c(1,0), each = 1000)


# count total word
result <- ntoken(df_text$text)
n_suc <- sum(result[1:1000])
n_fail <- sum(result[1001:2000])

senti_count <- df_text %>%
  group_by(success) %>%
  count(sentiment) 

senti_count$success <- factor(senti_count$success)

ggplot(senti_count) +
  geom_bar(aes(x = factor(sentiment), y = n, fill = success),
           stat = 'identity', position = 'dodge') +
  scale_y_continuous(name = '', expand = c(0,0)) + 
  diy_theme +
  labs(title = "Blurbs' Sentiment and Success \n", 
          caption = '\n Source: Webrobots.io; Kickstarter') +
  theme(plot.subtitle = element_text(color = 'grey'),
        axis.line = element_blank(),
        axis.title = element_blank(),
        legend.position = c(.8, 1),
        legend.direction = 'horizontal',
        plot.title = element_text(hjust = .5, size = 25),
        panel.grid.major.y=element_line(size = .1, color = 'grey')) +
  scale_x_discrete(labels = c('negative', 'neutral', 'positive')) +
  scale_fill_manual(values=c("#575cfb", "#05ce78"))
```

There are more successful blurbs are rated as positive than failed blurbs, and also more successful blurbs rated as negative, while more failed blurbs are rated as neutral. 

Therefore, we could guess maybe the more sentimental the blurb is, the more likely it could succeed. 


```{r, echo=FALSE}
### b) Positive vs negative
df_text$positive <- as.numeric(df_text$sentiment > 0) 

df_2doc <- df_text %>%
  group_by(positive) %>%
  summarise(text = paste0(text, collapse = ';'))

df_senti <- data.frame(doc_id = df_2doc$positive, 
                       text = df_2doc$text, stringsAsFactors = F)
df_senti_corpus <- VCorpus(DataframeSource(df_senti))

# clean
clean_senti <- clean_corpus(df_senti_corpus)
# transfer to dtm
senti_dtm <- DocumentTermMatrix(clean_senti)
```

```{r, echo=FALSE}
senti_dt <- tidy(senti_dtm)

senti_tf_idf <- senti_dt %>% 
  bind_tf_idf(term, document, count) %>%
  group_by(document) %>%
  arrange(desc(tf_idf))
```

```{r, echo=FALSE, include=FALSE}
wordcloud2(senti_tf_idf[senti_tf_idf$document==1, c('term', 'tf_idf')], 
          shuffle = F, size = 1)
```

```{r, echo=FALSE, include=FALSE}
wordcloud2(senti_tf_idf[senti_tf_idf$document==0, c('term', 'tf_idf')], 
           shuffle = F, size = 1)
```

### b) Get in their mind

```{r, echo=FALSE}
nrc_dic <- tidytext::get_sentiments(lexicon = 'nrc')
# dim(nrc_dic)
# head(nrc_dic)
# unique(nrc_dic$sentiment)

nrc_count <- function(words, nrc_dic){
  require(quanteda)
  tok <- quanteda::tokens(words)
  trust.count <- sum(tok[[1]]%in%nrc_dic[nrc_dic$sentiment == 'trust',]$word)
  fear.count <- sum(tok[[1]]%in%nrc_dic[nrc_dic$sentiment == 'fear',]$word)
  negative.count <- sum(tok[[1]]%in%nrc_dic[nrc_dic$sentiment == 'negative',]$word)
  sadness.count <- sum(tok[[1]]%in%nrc_dic[nrc_dic$sentiment == 'sadness',]$word)
  anger.count <- sum(tok[[1]]%in%nrc_dic[nrc_dic$sentiment == 'anger',]$word)
  surprise.count <- sum(tok[[1]]%in%nrc_dic[nrc_dic$sentiment == 'surprise',]$word)
  positive.count <- sum(tok[[1]]%in%nrc_dic[nrc_dic$sentiment == 'positive',]$word)
  disgust.count <- sum(tok[[1]]%in%nrc_dic[nrc_dic$sentiment == 'disgust',]$word)
  joy.count <- sum(tok[[1]]%in%nrc_dic[nrc_dic$sentiment == 'joy',]$word)
  anticipation.count <- sum(tok[[1]]%in%nrc_dic[nrc_dic$sentiment == 'anticipation',]$word)
  out <- c(trust.count, fear.count, negative.count, sadness.count, 
                    anger.count, surprise.count, positive.count, disgust.count, 
                    joy.count, anticipation.count)
  return(out)
}
```

```{r nrc, cache=TRUE, echo=FALSE}
tmp <- sapply(df_text$text, function(x) nrc_count(x, nrc_dic))
#dim(tmp)
nrc_blurb <- t(tmp)
rownames(nrc_blurb) <- NULL
colnames(nrc_blurb) <- unique(nrc_dic$sentiment)

# first 1000 file is successful file
# colSums(nrc_blurb[1:1000,])

# last 1000 file is failed file
# colSums(nrc_blurb[1001:2000,])
```

```{r Q3c, echo=FALSE, fig.retina=2, fig.height=8, fig.width=12, fig.align='center'}
df_nrc <- data.frame(success = rep(0:1, each = 10), 
                     count=c(colSums(nrc_blurb[1001:2000,]), colSums(nrc_blurb[1:1000,])),
                     emotion = rep(unique(nrc_dic$sentiment), 2))

df_nrc$success <- factor(df_nrc$success)

ggplot(df_nrc) +
  geom_bar(position = 'dodge', stat = 'identity',
           aes(x = emotion, y = count, fill = success)) +
  theme_economist_white(gray_bg = F) +
  labs(x = '', y ='') +
  scale_y_continuous(name = '', expand = c(0,0)) + 
  diy_theme +
  labs(title = "NRC 10 Emotion and Successful Blurbs \n", 
          caption = '\n Source: Webrobots.io; Kickstarter') +
  theme(plot.subtitle = element_text(color = 'grey'),
        axis.line = element_blank(),
        axis.title = element_blank(),
        legend.position = c(.5, 1),
        legend.direction = 'horizontal',
        plot.title = element_text(hjust = .5, size = 25),
        panel.grid.major.y=element_line(size = .1, color = 'grey')) +
  scale_fill_manual(values=c("#575cfb", "#05ce78"))
```

As the result graph shows, successful blurbs have more words alluding **anticipation**, **surprise**, but failed projects include more **anger**, **disgust**, **fear**, **negative**, **positive** and **trust**, while they have similar amount of **joy** and **sadness**.




